{
  "schema_version": 1,
  "meta": {
    "run_id": "20260219T011126Z",
    "generated_at": "2026-02-19T01:11:26.158Z",
    "source_repo": {
      "full_name": "fastrepl/char",
      "url": "https://github.com/fastrepl/char"
    },
    "topics": [
      "local-first",
      "notetaking",
      "open-source",
      "react",
      "rust",
      "tauri",
      "typescript"
    ]
  },
  "app": {
    "name": "Char",
    "one_sentence": "An AI notepad for private meetings that listens to audio and generates summaries based on user memos.",
    "inspired_by": null
  },
  "core_loop": "User jots down important notes during a meeting while Char listens to audio input/output from the computer; after the meeting, Char crafts a summary based on the user's memos and the transcribed audio.",
  "screens": [
    {
      "id": "main",
      "name": "Main Notepad",
      "purpose": "Allows users to take notes during meetings while Char captures audio in the background.",
      "primary_actions": [
        "Jot down memo",
        "View real-time transcription",
        "Generate post-meeting summary"
      ]
    }
  ],
  "rust_commands": [
    {
      "name": "save_item",
      "purpose": "Persist a memo or note item to local storage.",
      "async": true,
      "input": {},
      "output": {}
    }
  ],
  "data_model": {
    "tables": [
      {
        "name": "memos",
        "fields": [
          {
            "name": "id",
            "type": "string"
          },
          {
            "name": "content",
            "type": "string"
          },
          {
            "name": "timestamp",
            "type": "datetime"
          }
        ]
      }
    ]
  },
  "tauri_capabilities": [],
  "mvp_plan": {
    "milestones": [
      {
        "week": 1,
        "tasks": [
          "Set up Tauri + Rust backend",
          "Implement basic audio capture",
          "Create main notepad UI"
        ]
      }
    ]
  },
  "acceptance_tests": [
    "User can open the app and start taking notes during a simulated meeting.",
    "After ending a session, a summary is generated using local LLM (e.g., Ollama)."
  ],
  "open_questions": [
    "How to handle offline transcription without cloud services?",
    "What local LLMs are officially supported?"
  ],
  "scores": {
    "closure": 3,
    "feasibility": 3,
    "stack_fit": 3,
    "complexity_control": 3,
    "debuggability": 3,
    "demo_value": 3
  },
  "overall_recommendation": "go",
  "citations": {
    "app": [
      "E-RD-002"
    ],
    "core_loop": [
      "E-RD-003"
    ],
    "screens": {
      "main": [
        "E-RD-006"
      ]
    },
    "commands": {
      "save_item": [
        "E-RF-001"
      ]
    },
    "tables": {
      "memos": [
        "E-RD-002"
      ]
    },
    "acceptance_tests": {
      "0": [
        "E-RL-001"
      ],
      "1": [
        "E-RD-004"
      ]
    }
  }
}
